= Cohere Multimodal Embeddings

Cohere supports two types of embeddings models, text and multimodal.
This document describes how to create multimodal embeddings using the Cohere link:https://docs.cohere.com/docs/embeddings[Multimodal embeddings API].

The multimodal embeddings model generates 1536-dimension vectors based on the input you provide, which can include a combination of image and text data.
The embedding vectors can then be used for subsequent tasks like image classification or visual search.

The image embedding vector and text embedding vector are in the same semantic space with the same dimensionality.
Consequently, these vectors can be used interchangeably for use cases like searching images by text, or searching text by image.

NOTE: The Cohere Multimodal API imposes the following limits: maximum 1 image per request, maximum 5MB per image, supported formats are JPEG, PNG, WebP, and GIF.

TIP: For text-only embedding use cases, we recommend using the xref:api/embeddings/cohere-embeddings-text.adoc[Cohere text-embeddings model] instead.

== Prerequisites

You will need to create an API key with Cohere to access Cohere embedding models.

Create an account at https://dashboard.cohere.com/welcome/register[Cohere registration page] and generate the token on the https://dashboard.cohere.com/api-keys[API Keys page].

The Spring AI project defines a configuration property named `spring.ai.cohere.api-key` that you should set to the value of the API Key obtained from dashboard.cohere.com.

You can set this configuration property in your `application.properties` file:

[source,properties]
----
spring.ai.cohere.api-key=<your-cohere-api-key>
----

For enhanced security when handling sensitive information like API keys, you can use Spring Expression Language (SpEL) to reference an environment variable:

[source,yaml]
----
# In application.yml
spring:
  ai:
    cohere:
      api-key: ${COHERE_API_KEY}
----

[source,bash]
----
# In your environment or .env file
export COHERE_API_KEY=<your-cohere-api-key>
----

You can also set this configuration programmatically in your application code:

[source,java]
----
// Retrieve API key from a secure source or environment variable
String apiKey = System.getenv("COHERE_API_KEY");
----

=== Add Repositories and BOM

Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.
Refer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.

To help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.


== Auto-configuration

[NOTE]
====
There has been a significant change in the Spring AI auto-configuration, starter modules' artifact names.
Please refer to the https://docs.spring.io/spring-ai/reference/upgrade-notes.html[upgrade notes] for more information.
====

Spring AI provides Spring Boot auto-configuration for the Cohere Multimodal Embedding Model.
To enable it add the following dependency to your project's Maven `pom.xml` file:

[source, xml]
----
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-starter-model-cohere</artifactId>
</dependency>
----

or to your Gradle `build.gradle` build file.

[source,groovy]
----
dependencies {
    implementation 'org.springframework.ai:spring-ai-starter-model-cohere'
}
----

TIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.

=== Embedding Properties

==== Retry Properties

The prefix `spring.ai.retry` is used as the property prefix that lets you configure the retry mechanism for the Cohere Multimodal Embedding model.

[cols="3,5,1", stripes=even]
|====
| Property | Description | Default

| spring.ai.retry.max-attempts   | Maximum number of retry attempts. |  10
| spring.ai.retry.backoff.initial-interval | Initial sleep duration for the exponential backoff policy. |  2 sec.
| spring.ai.retry.backoff.multiplier | Backoff interval multiplier. |  5
| spring.ai.retry.backoff.max-interval | Maximum backoff duration. |  3 min.
| spring.ai.retry.on-client-errors | If false, throw a NonTransientAiException, and do not attempt retry for `4xx` client error codes | false
| spring.ai.retry.exclude-on-http-codes | List of HTTP status codes that should not trigger a retry (e.g. to throw NonTransientAiException). | empty
| spring.ai.retry.on-http-codes | List of HTTP status codes that should trigger a retry (e.g. to throw TransientAiException). | empty
|====

==== Connection Properties

The prefix `spring.ai.cohere` is used as the property prefix that lets you connect to Cohere.

[cols="3,5,1", stripes=even]
|====
| Property | Description | Default

| spring.ai.cohere.base-url   | The URL to connect to |  https://api.cohere.com
| spring.ai.cohere.api-key    | The API Key           |  -
|====

==== Configuration Properties

[NOTE]
====
Enabling and disabling of the multimodal embedding auto-configurations are now configured via top level properties with the prefix `spring.ai.model.embedding.multimodal`.

To enable, spring.ai.model.embedding.multimodal=cohere (It is enabled by default)

To disable, spring.ai.model.embedding.multimodal=none (or any value which doesn't match cohere)

This change is done to allow configuration of multiple models.
====

The prefix `spring.ai.cohere.embedding.multimodal` is the property prefix that configures the multimodal `EmbeddingModel` implementation for Cohere.

[cols="3,5,1", stripes=even]
|====
| Property | Description | Default

| spring.ai.model.embedding.multimodal | Enable Cohere multimodal embedding model.  | cohere
| spring.ai.cohere.embedding.multimodal.base-url   | Optional overrides the spring.ai.cohere.base-url to provide embedding specific url | -
| spring.ai.cohere.embedding.multimodal.api-key    | Optional overrides the spring.ai.cohere.api-key to provide embedding specific api-key  | -
| spring.ai.cohere.embedding.multimodal.options.model      | The model to use      | embed-v4
| spring.ai.cohere.embedding.multimodal.options.input-type | The type of input (search_document, search_query, classification, clustering) | classification
| spring.ai.cohere.embedding.multimodal.options.embedding-types | The types of embeddings to return (float, int8, uint8, binary, ubinary) | [float]
| spring.ai.cohere.embedding.multimodal.options.truncate | How to handle inputs longer than maximum token length (NONE, START, END) | -
|====

NOTE: You can override the common `spring.ai.cohere.base-url` and `spring.ai.cohere.api-key` for the `ChatModel` and `EmbeddingModel` implementations.
The `spring.ai.cohere.embedding.multimodal.base-url` and `spring.ai.cohere.embedding.multimodal.api-key` properties if set take precedence over the common properties.
Similarly, the `spring.ai.cohere.chat.base-url` and `spring.ai.cohere.chat.api-key` properties if set take precedence over the common properties.
This is useful if you want to use different Cohere accounts for different models and different model endpoints.

TIP: All properties prefixed with `spring.ai.cohere.embedding.multimodal.options` can be overridden at runtime by adding a request specific <<embedding-options>> to the `DocumentEmbeddingRequest` call.

== Runtime Options [[embedding-options]]

The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-cohere/src/main/java/org/springframework/ai/cohere/embedding/CohereMultimodalEmbeddingOptions.java[CohereMultimodalEmbeddingOptions.java] provides the Cohere multimodal configurations, such as the model to use and etc.

The default options can be configured using the `spring.ai.cohere.embedding.multimodal.options` properties as well.

At start-time use the `CohereMultimodalEmbeddingModel` constructor to set the default options used for all embedding requests.
At run-time you can override the default options, using a `CohereMultimodalEmbeddingOptions` instance as part of your `DocumentEmbeddingRequest`.

For example to override the default model name and input type for a specific request:

[source,java]
----
// Create a document with text only
Document textDocument = new Document("Hello World");

// Create a document with an image
Media imageMedia = new Media(MimeTypeUtils.IMAGE_PNG, new ClassPathResource("/test.image.png"));
Document imageDocument = new Document("", List.of(imageMedia), Map.of());

// Create a document with both text and image
Document multimodalDocument = new Document("Describe this image", List.of(imageMedia), Map.of());

// Create embedding request with custom options
DocumentEmbeddingRequest embeddingRequest = new DocumentEmbeddingRequest(
    List.of(textDocument, imageDocument, multimodalDocument),
    CohereMultimodalEmbeddingOptions.builder()
        .model("embed-v4")
        .inputType(InputType.CLASSIFICATION)
        .build());

EmbeddingResponse embeddingResponse = embeddingModel.call(embeddingRequest);
----

== Understanding Input Types

Cohere embeddings support different input types to optimize the embeddings for specific use cases:

* `SEARCH_DOCUMENT`: Use when embedding documents to be retrieved in a search system
* `SEARCH_QUERY`: Use when embedding search queries to match against documents
* `CLASSIFICATION`: Use for classification tasks (text or image classification)
* `CLUSTERING`: Use for clustering documents or images by similarity

For best results in semantic search applications, use `SEARCH_DOCUMENT` for your corpus (both text and images) and `SEARCH_QUERY` for user queries.

== Image Format Requirements

When working with images in Cohere multimodal embeddings, note the following requirements:

* Maximum 1 image per request
* Maximum 5MB per image
* Supported formats: JPEG, PNG, WebP, GIF
* Images are converted to Data URI format (base64-encoded) before sending to the API

The Spring AI Cohere integration handles the conversion automatically when you provide images through `Media` objects.

== Sample Controller

This will create a `DocumentEmbeddingModel` implementation that you can inject into your class.
Here is an example of a simple `@Controller` class that uses the multimodal embedding implementation.

[source,application.properties]
----
spring.ai.cohere.api-key=YOUR_API_KEY
spring.ai.model.embedding.multimodal=cohere
spring.ai.cohere.embedding.multimodal.options.model=embed-v4
spring.ai.cohere.embedding.multimodal.options.input-type=classification
----

[source,java]
----
@RestController
public class MultimodalEmbeddingController {

    private final DocumentEmbeddingModel embeddingModel;

    @Autowired
    public MultimodalEmbeddingController(DocumentEmbeddingModel embeddingModel) {
        this.embeddingModel = embeddingModel;
    }

    @GetMapping("/ai/embedding/text")
    public Map embedText(@RequestParam(value = "message", defaultValue = "Hello World") String message) {
        Document document = new Document(message);
        DocumentEmbeddingRequest request = new DocumentEmbeddingRequest(
            List.of(document),
            EmbeddingOptions.EMPTY);

        EmbeddingResponse embeddingResponse = this.embeddingModel.call(request);
        return Map.of("embedding", embeddingResponse);
    }

    @PostMapping("/ai/embedding/image")
    public Map embedImage(@RequestParam("file") MultipartFile file) throws IOException {
        Media imageMedia = new Media(
            MimeTypeUtils.parseMimeType(file.getContentType()),
            file.getResource());

        Document document = new Document("", List.of(imageMedia), Map.of());
        DocumentEmbeddingRequest request = new DocumentEmbeddingRequest(
            List.of(document),
            EmbeddingOptions.EMPTY);

        EmbeddingResponse embeddingResponse = this.embeddingModel.call(request);
        return Map.of("embedding", embeddingResponse);
    }

    @PostMapping("/ai/embedding/multimodal")
    public Map embedMultimodal(
            @RequestParam(value = "message", defaultValue = "Describe this image") String message,
            @RequestParam("file") MultipartFile file) throws IOException {

        Media imageMedia = new Media(
            MimeTypeUtils.parseMimeType(file.getContentType()),
            file.getResource());

        Document document = new Document(message, List.of(imageMedia), Map.of());
        DocumentEmbeddingRequest request = new DocumentEmbeddingRequest(
            List.of(document),
            EmbeddingOptions.EMPTY);

        EmbeddingResponse embeddingResponse = this.embeddingModel.call(request);
        return Map.of("embedding", embeddingResponse);
    }
}
----

== Manual Configuration

If you are not using Spring Boot, you can manually configure the Cohere Multimodal Embedding Model.
For this add the `spring-ai-cohere` dependency to your project's Maven `pom.xml` file:

[source, xml]
----
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-cohere</artifactId>
</dependency>
----

or to your Gradle `build.gradle` build file.

[source,groovy]
----
dependencies {
    implementation 'org.springframework.ai:spring-ai-cohere'
}
----

TIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.

NOTE: The `spring-ai-cohere` dependency provides access also to the `CohereChatModel`.
For more information about the `CohereChatModel` refer to the link:../chat/cohere-chat.html[Cohere Chat Client] section.

Next, create a `CohereMultimodalEmbeddingModel` instance and use it to compute embeddings for text and images:

[source,java]
----
var cohereApi = new CohereApi(System.getenv("COHERE_API_KEY"));

var embeddingModel = CohereMultimodalEmbeddingModel.builder()
    .cohereApi(cohereApi)
    .options(CohereMultimodalEmbeddingOptions.builder()
        .model("embed-v4")
        .inputType(InputType.CLASSIFICATION)
        .embeddingTypes(List.of(EmbeddingType.FLOAT))
        .build())
    .build();

// Embedding text
Document textDocument = new Document("Hello World");

// Embedding an image
Media imageMedia = new Media(MimeTypeUtils.IMAGE_PNG, new ClassPathResource("/test.image.png"));
Document imageDocument = new Document("", List.of(imageMedia), Map.of());

// Embedding text with image
Document multimodalDocument = new Document("Describe this image", List.of(imageMedia), Map.of());

DocumentEmbeddingRequest embeddingRequest = new DocumentEmbeddingRequest(
    List.of(textDocument, imageDocument, multimodalDocument),
    EmbeddingOptions.EMPTY);

EmbeddingResponse embeddingResponse = embeddingModel.call(embeddingRequest);

// Each document gets its own embedding result
assertThat(embeddingResponse.getResults()).hasSize(3);
assertThat(embeddingResponse.getResults().get(0).getOutput()).hasSize(1536);
----

The `CohereMultimodalEmbeddingOptions` provides the configuration information for the embedding requests.
The options class offers a `builder()` for easy options creation.
