= Anthropic SDK Chat (Official)

Spring AI supports Anthropic's Claude models through the official Anthropic Java SDK, providing access to Claude through Anthropic's API.

NOTE: This implementation uses the official link:https://github.com/anthropics/anthropic-sdk-java[Anthropic Java SDK] from Anthropic. For the alternative Spring AI implementation, see xref:api/chat/anthropic-chat.adoc[Anthropic Chat].

== Prerequisites

Create an account at the https://console.anthropic.com/[Anthropic Console] and generate an API key on the https://console.anthropic.com/settings/keys[API Keys page].

=== Add Repositories and BOM

Spring AI artifacts are published in Maven Central and Spring Snapshot repositories.
Refer to the xref:getting-started.adoc#artifact-repositories[Artifact Repositories] section to add these repositories to your build system.

To help with dependency management, Spring AI provides a BOM (bill of materials) to ensure that a consistent version of Spring AI is used throughout the entire project. Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build system.

== Manual Configuration

NOTE: Auto-configuration support with a Spring Boot starter is planned for a future release. Currently, manual configuration is required.

The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-anthropic-sdk/src/main/java/org/springframework/ai/anthropicsdk/AnthropicSdkChatModel.java[AnthropicSdkChatModel] implements the `ChatModel` interface and uses the official Anthropic Java SDK to connect to Claude.

Add the `spring-ai-anthropic-sdk` dependency to your project's Maven `pom.xml` file:

[source, xml]
----
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-anthropic-sdk</artifactId>
</dependency>
----

or to your Gradle `build.gradle` build file:

[source,groovy]
----
dependencies {
    implementation 'org.springframework.ai:spring-ai-anthropic-sdk'
}
----

TIP: Refer to the xref:getting-started.adoc#dependency-management[Dependency Management] section to add the Spring AI BOM to your build file.

=== Authentication

Configure your API key either programmatically or via environment variable:

[source,java]
----
var chatOptions = AnthropicSdkChatOptions.builder()
    .model("claude-sonnet-4-20250514")
    .maxTokens(1024)
    .apiKey(System.getenv("ANTHROPIC_API_KEY"))
    .build();

var chatModel = new AnthropicSdkChatModel(chatOptions);
----

Or set the environment variable and let the SDK auto-detect it:

[source,bash]
----
export ANTHROPIC_API_KEY=<your-api-key>
----

[source,java]
----
// API key will be detected from ANTHROPIC_API_KEY environment variable
var chatModel = new AnthropicSdkChatModel(
    AnthropicSdkChatOptions.builder()
        .model("claude-sonnet-4-20250514")
        .maxTokens(1024)
        .build());
----

=== Basic Usage

[source,java]
----
ChatResponse response = chatModel.call(
    new Prompt("Generate the names of 5 famous pirates."));

// Or with streaming responses
Flux<ChatResponse> stream = chatModel.stream(
    new Prompt("Generate the names of 5 famous pirates."));
----

== Runtime Options [[chat-options]]

The https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-anthropic-sdk/src/main/java/org/springframework/ai/anthropicsdk/AnthropicSdkChatOptions.java[AnthropicSdkChatOptions.java] class provides model configurations such as the model to use, temperature, max tokens, etc.

On start-up, configure default options with the `AnthropicSdkChatModel(options)` constructor.

At run-time, you can override the default options by adding new, request-specific options to the `Prompt` call.
For example, to override the default model and temperature for a specific request:

[source,java]
----
ChatResponse response = chatModel.call(
    new Prompt(
        "Generate the names of 5 famous pirates.",
        AnthropicSdkChatOptions.builder()
            .model("claude-sonnet-4-20250514")
            .temperature(0.4)
        .build()
    ));
----

=== Chat Options

[cols="3,5,1", stripes=even]
|====
| Option | Description | Default

| model | Name of the Claude model to use. Models include: `claude-sonnet-4-20250514`, `claude-opus-4-20250514`, `claude-3-5-sonnet-20241022`, `claude-3-5-haiku-20241022`, etc. See https://docs.anthropic.com/en/docs/about-claude/models[Claude Models]. | `claude-sonnet-4-20250514`
| maxTokens | The maximum number of tokens to generate in the response. | 4096
| temperature | Controls randomness in the response. Higher values make output more random, lower values make it more deterministic. Range: 0.0-1.0 | 1.0
| topP | Nucleus sampling parameter. The model considers tokens with top_p probability mass. | -
| topK | Only sample from the top K options for each token. | -
| stopSequences | Custom sequences that will cause the model to stop generating. | -
| apiKey | The API key for authentication. Auto-detects from `ANTHROPIC_API_KEY` environment variable if not set. | -
| baseUrl | The base URL for the Anthropic API. | https://api.anthropic.com
| timeout | Request timeout duration. | 60 seconds
| maxRetries | Maximum number of retry attempts for failed requests. | 2
| proxy | Proxy settings for the HTTP client. | -
| customHeaders | Custom HTTP headers to include in requests. | -
| thinking | Thinking configuration. Use the convenience builders `thinkingEnabled(budgetTokens)`, `thinkingAdaptive()`, or `thinkingDisabled()`, or pass a raw `ThinkingConfigParam`. | -
|====

=== Tool Calling Options

[cols="3,5,1", stripes=even]
|====
| Option | Description | Default

| toolChoice | Controls which tool (if any) is called by the model. Use `ToolChoiceAuto`, `ToolChoiceAny`, `ToolChoiceTool`, or `ToolChoiceNone`. | AUTO
| toolCallbacks | List of tool callbacks to register with the model. | -
| toolNames | Set of tool names to be resolved at runtime. | -
| internalToolExecutionEnabled | If false, tool calls are proxied to the client for manual handling. If true, Spring AI handles tool calls internally. | true
| disableParallelToolUse | When true, the model will use at most one tool per response. | false
|====

TIP: In addition to the model-specific https://github.com/spring-projects/spring-ai/blob/main/models/spring-ai-anthropic-sdk/src/main/java/org/springframework/ai/anthropicsdk/AnthropicSdkChatOptions.java[AnthropicSdkChatOptions], you can use a portable link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/ChatOptions.java[ChatOptions] instance, created with link:https://github.com/spring-projects/spring-ai/blob/main/spring-ai-model/src/main/java/org/springframework/ai/chat/prompt/DefaultChatOptionsBuilder.java[ChatOptions#builder()].

== Tool Calling

You can register custom Java functions or methods with the `AnthropicSdkChatModel` and have Claude intelligently choose to output a JSON object containing arguments to call one or many of the registered functions/tools.
This is a powerful technique to connect the LLM capabilities with external tools and APIs.
Read more about xref:api/tools.adoc[Tool Calling].

=== Basic Tool Calling

[source,java]
----
var chatOptions = AnthropicSdkChatOptions.builder()
    .model("claude-sonnet-4-20250514")
    .toolCallbacks(List.of(
        FunctionToolCallback.builder("getCurrentWeather", new WeatherService())
            .description("Get the weather in location")
            .inputType(WeatherService.Request.class)
            .build()))
    .build();

var chatModel = new AnthropicSdkChatModel(chatOptions);

ChatResponse response = chatModel.call(
    new Prompt("What's the weather like in San Francisco?", chatOptions));
----

=== Tool Choice Options

Control how Claude uses tools with the `toolChoice` option:

[source,java]
----
import com.anthropic.models.messages.ToolChoiceAny;
import com.anthropic.models.messages.ToolChoiceTool;
import com.anthropic.models.messages.ToolChoiceNone;

// Force Claude to use any available tool
var options = AnthropicSdkChatOptions.builder()
    .toolChoice(ToolChoiceAny.builder().build())
    .toolCallbacks(...)
    .build();

// Force Claude to use a specific tool
var options = AnthropicSdkChatOptions.builder()
    .toolChoice(ToolChoiceTool.builder().name("getCurrentWeather").build())
    .toolCallbacks(...)
    .build();

// Prevent tool use entirely
var options = AnthropicSdkChatOptions.builder()
    .toolChoice(ToolChoiceNone.builder().build())
    .toolCallbacks(...)
    .build();
----

[TIP]
====
The Anthropic Java SDK provides convenient static factory methods for common tool choices, which can make your code more concise:

* `ToolChoice.auto()` can be used instead of `ToolChoice.ofAuto(...)`.
* `ToolChoice.any()` can be used instead of `ToolChoice.ofAny(...)`.
* `ToolChoice.none()` can be used instead of `ToolChoice.ofNone(...)`.
====

=== Streaming Tool Calling

The Anthropic SDK module fully supports tool calling in streaming mode. When Claude decides to call a tool during streaming:

1. Tool call arguments are accumulated from partial JSON deltas
2. Tools are executed when the content block completes
3. Results are sent back to Claude
4. The conversation continues recursively until Claude provides a final response

[source,java]
----
Flux<ChatResponse> stream = chatModel.stream(
    new Prompt("What's the weather in Paris, Tokyo, and New York?", chatOptions));

String response = stream
    .collectList()
    .block()
    .stream()
    .map(r -> r.getResult().getOutput().getContent())
    .filter(Objects::nonNull)
    .collect(Collectors.joining());
----

== Streaming

The Anthropic SDK module supports both synchronous and streaming responses. Streaming allows Claude to return responses incrementally as they're generated.

[source,java]
----
Flux<ChatResponse> stream = chatModel.stream(new Prompt("Tell me a story"));

stream.subscribe(response -> {
    String content = response.getResult().getOutput().getContent();
    if (content != null) {
        System.out.print(content);
    }
});
----

== Extended Thinking

Anthropic Claude models support a "thinking" feature that allows the model to show its reasoning process before providing a final answer. This is especially useful for complex questions that require step-by-step reasoning, such as math, logic, and analysis tasks.

[NOTE]
====
*Supported Models*

The thinking feature is supported by the following Claude models:

* Claude 4 models (`claude-opus-4-20250514`, `claude-sonnet-4-20250514`)
* Claude 3.7 Sonnet (`claude-3-7-sonnet-20250219`)

*Model capabilities:*

* *Claude 3.7 Sonnet*: Returns full thinking output.
* *Claude 4 models*: Support summarized thinking and enhanced tool integration.

API request structure is the same across all supported models, but output behavior varies.
====

=== Thinking Configuration

To enable thinking, configure the following:

1. **Set a thinking budget**: The `budgetTokens` must be >= 1024 and less than `maxTokens`.
2. **Set temperature to 1.0**: Required when thinking is enabled.

=== Convenience Builder Methods

`AnthropicSdkChatOptions.Builder` provides convenience methods for the three thinking modes:

[source,java]
----
// Enable thinking with a specific token budget
var options = AnthropicSdkChatOptions.builder()
    .model("claude-sonnet-4-20250514")
    .temperature(1.0)
    .maxTokens(16000)
    .thinkingEnabled(10000L)    // budget must be >= 1024 and < maxTokens
    .build();

// Let Claude adaptively decide whether to think
var options = AnthropicSdkChatOptions.builder()
    .model("claude-sonnet-4-20250514")
    .thinkingAdaptive()
    .build();

// Explicitly disable thinking
var options = AnthropicSdkChatOptions.builder()
    .model("claude-sonnet-4-20250514")
    .thinkingDisabled()
    .build();
----

You can also use the raw SDK `ThinkingConfigParam` directly:

[source,java]
----
import com.anthropic.models.messages.ThinkingConfigParam;
import com.anthropic.models.messages.ThinkingConfigEnabled;

var options = AnthropicSdkChatOptions.builder()
    .thinking(ThinkingConfigParam.ofEnabled(
        ThinkingConfigEnabled.builder().budgetTokens(10000L).build()))
    .build();
----

=== Non-streaming Example

[source,java]
----
var options = AnthropicSdkChatOptions.builder()
    .model("claude-sonnet-4-20250514")
    .temperature(1.0)
    .maxTokens(16000)
    .thinkingEnabled(10000L)
    .build();

ChatResponse response = chatModel.call(
    new Prompt("Are there an infinite number of prime numbers such that n mod 4 == 3?", options));

// The response contains multiple generations:
// - ThinkingBlock generations (with "signature" in metadata)
// - TextBlock generations (with the final answer)
for (Generation generation : response.getResults()) {
    AssistantMessage message = generation.getOutput();
    if (message.getMetadata().containsKey("signature")) {
        // This is a thinking block - contains Claude's reasoning
        System.out.println("Thinking: " + message.getText());
        System.out.println("Signature: " + message.getMetadata().get("signature"));
    }
    else if (message.getMetadata().containsKey("data")) {
        // This is a redacted thinking block (safety-redacted reasoning)
        System.out.println("Redacted thinking data: " + message.getMetadata().get("data"));
    }
    else if (message.getText() != null && !message.getText().isBlank()) {
        // This is the final text response
        System.out.println("Answer: " + message.getText());
    }
}
----

=== Streaming Example

Thinking is fully supported in streaming mode. Thinking deltas and signature deltas are emitted as they arrive:

[source,java]
----
var options = AnthropicSdkChatOptions.builder()
    .model("claude-sonnet-4-20250514")
    .temperature(1.0)
    .maxTokens(16000)
    .thinkingEnabled(10000L)
    .build();

Flux<ChatResponse> stream = chatModel.stream(
    new Prompt("Are there an infinite number of prime numbers such that n mod 4 == 3?", options));

stream.subscribe(response -> {
    Generation generation = response.getResult();
    AssistantMessage message = generation.getOutput();

    if (message.getMetadata().containsKey("thinking")) {
        // Incremental thinking content
        System.out.print(message.getText());
    }
    else if (message.getMetadata().containsKey("signature")) {
        // Thinking block signature (emitted at end of thinking)
        System.out.println("\nSignature: " + message.getMetadata().get("signature"));
    }
    else if (message.getText() != null) {
        // Final text content
        System.out.print(message.getText());
    }
});
----

=== Response Structure

When thinking is enabled, the response contains different types of content:

[cols="2,3,3", stripes=even]
|====
| Content Type | Metadata Key | Description

| **Thinking Block** | `signature` | Claude's reasoning text with a cryptographic signature. In sync mode, the thinking text is in `getText()` and the signature is in `getMetadata().get("signature")`.
| **Redacted Thinking** | `data` | Safety-redacted reasoning. Contains only a `data` marker, no visible text.
| **Signature (streaming)** | `signature` | In streaming mode, the signature arrives as a separate delta at the end of a thinking block.
| **Thinking Delta (streaming)** | `thinking` | Incremental thinking text chunks during streaming. The `thinking` metadata key is set to `true`.
| **Text Block** | _(none)_ | The final answer text in `getText()`.
|====

== Multi-Modal Support

The Anthropic SDK module supports multi-modal inputs, allowing you to send images and PDF documents alongside text in your prompts.

=== Image Input

Send images to Claude for analysis using the `Media` class:

[source,java]
----
var imageResource = new ClassPathResource("/test-image.png");

var userMessage = UserMessage.builder()
    .text("What do you see in this image?")
    .media(List.of(new Media(MimeTypeUtils.IMAGE_PNG, imageResource)))
    .build();

ChatResponse response = chatModel.call(new Prompt(List.of(userMessage)));
----

Supported image formats: PNG, JPEG, GIF, WebP. Images can be provided as:

* Byte arrays (automatically base64-encoded)
* HTTPS URLs (passed directly to the API)

=== PDF Document Input

Send PDF documents for Claude to analyze:

[source,java]
----
var pdfResource = new ClassPathResource("/document.pdf");

var userMessage = UserMessage.builder()
    .text("Please summarize this document.")
    .media(List.of(new Media(new MimeType("application", "pdf"), pdfResource)))
    .build();

ChatResponse response = chatModel.call(new Prompt(List.of(userMessage)));
----

=== Multiple Media Items

You can include multiple images or documents in a single message:

[source,java]
----
var userMessage = UserMessage.builder()
    .text("Compare these two images.")
    .media(List.of(
        new Media(MimeTypeUtils.IMAGE_PNG, image1Resource),
        new Media(MimeTypeUtils.IMAGE_PNG, image2Resource)))
    .build();
----

== Sample Controller

Here is an example of a simple `@RestController` class that uses the chat model for text generations:

[source,java]
----
@RestController
public class ChatController {

    private final AnthropicSdkChatModel chatModel;

    public ChatController() {
        var options = AnthropicSdkChatOptions.builder()
            .model("claude-sonnet-4-20250514")
            .maxTokens(1024)
            .apiKey(System.getenv("ANTHROPIC_API_KEY"))
            .build();
        this.chatModel = new AnthropicSdkChatModel(options);
    }

    @GetMapping("/ai/generate")
    public Map<String, String> generate(
            @RequestParam(value = "message", defaultValue = "Tell me a joke") String message) {
        return Map.of("generation", chatModel.call(message));
    }

    @GetMapping("/ai/generateStream")
    public Flux<ChatResponse> generateStream(
            @RequestParam(value = "message", defaultValue = "Tell me a joke") String message) {
        Prompt prompt = new Prompt(new UserMessage(message));
        return chatModel.stream(prompt);
    }
}
----

== Key Differences from Spring AI Anthropic

This implementation differs from the xref:api/chat/anthropic-chat.adoc[Spring AI Anthropic] implementation in several ways:

[cols="2,3,3", stripes=even]
|====
| Aspect | Official Anthropic SDK | Existing Anthropic

| **HTTP Client** | OkHttp (via official SDK) | Spring RestClient/WebClient
| **API Updates** | Automatic via SDK updates | Manual maintenance
| **Multi-Modal** | Fully supported | Fully supported
| **Extended Thinking** | Fully supported | Fully supported
| **Prompt Caching** | Not yet supported | Fully supported
| **Auto-Configuration** | Not yet available | Full Spring Boot starter
| **Dependencies** | Official Anthropic SDK | Spring WebFlux
|====

**When to use Anthropic SDK:**

* You're starting a new project and want official SDK support
* You want automatic API updates from Anthropic
* You prefer using the official SDK directly

**When to use Spring AI Anthropic:**

* You need prompt caching
* You want full Spring Boot auto-configuration
* You have an existing project using it

== Observability

The Anthropic SDK implementation supports Spring AI's observability features through Micrometer.
All chat model operations are instrumented for monitoring and tracing.

== Logging

Enable SDK logging by setting the environment variable:

[source,bash]
----
export ANTHROPIC_LOG=debug
----

== Limitations

The following features are not yet supported in the Anthropic SDK implementation:

* Prompt caching
* Amazon Bedrock backend
* Google Vertex AI backend
* Spring Boot auto-configuration

These features are either available in the xref:api/chat/anthropic-chat.adoc[Spring AI Anthropic] implementation or planned for future releases.

== Additional Resources

* link:https://github.com/anthropics/anthropic-sdk-java[Official Anthropic Java SDK]
* link:https://docs.anthropic.com/[Anthropic API Documentation]
* link:https://docs.anthropic.com/en/docs/about-claude/models[Claude Models]
